{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "t_max = 2**8\n",
    "run_time = 4*t_max\n",
    "dims = (1,10,10,2)\n",
    "n_outputs = 100\n",
    "weight_e = 500\n",
    "weight_acc = 128\n",
    "weight_args = {'weight_e':weight_e, 'weight_acc':weight_acc}\n",
    "\n",
    "np.random.seed(seed=47)\n",
    "weights = (np.random.rand(n_outputs,np.product(dims)//2) - 0.5) / 5\n",
    "biases = (np.random.rand(n_outputs) - 0.5) / 2\n",
    "\n",
    "loihi_model = quartz.Network([\n",
    "    layers.InputLayer(dims=dims, **weight_args),\n",
    "    layers.FullyConnected(weights=weights, biases=None, **weight_args),\n",
    "    layers.MonitorLayer(**weight_args),\n",
    "    ])\n",
    "\n",
    "values = np.random.rand(np.product(dims)//2)\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "\n",
    "quantized_values = (values*t_max).round()/t_max\n",
    "quantized_weights = (weight_acc*weights).round()/weight_acc\n",
    "quantized_biases = (biases*t_max).round()/t_max\n",
    "\n",
    "model = nn.Sequential(nn.Linear(in_features=np.product(dims[1:3]), out_features=n_outputs), nn.ReLU())\n",
    "model[0].weight = torch.nn.Parameter(torch.tensor(quantized_weights))\n",
    "model[0].bias = torch.nn.Parameter(torch.tensor(quantized_biases))\n",
    "model_output = model(torch.tensor(quantized_values)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30800"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loihi_model.n_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/homes/glenz/STICK_on_loihi/stick/network.py\u001b[0m(49)\u001b[0;36mbuild_loihi_layered_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     48 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 49 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     50 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.prev_layer.blocks[0].neurons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fc:l1-n  0-calc, fc:l1-n  0-sync, fc:l1-n  0-first, fc:l1-n  0-second, fc:l1-n  0-output]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.prev_layer.blocks[0].neurons[0].loihi_type\n",
      "ipdb>  self.model.neurons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fc:l1-n  0-output-monitor, fc:l1-n  1-output-monitor, fc:l1-n  2-output-monitor, fc:l1-n  3-output-monitor, fc:l1-n  4-output-monitor, fc:l1-n  5-output-monitor, fc:l1-n  6-output-monitor, fc:l1-n  7-output-monitor, fc:l1-n  8-output-monitor, fc:l1-n  9-output-monitor, fc:l1-n 10-output-monitor, fc:l1-n 11-output-monitor, fc:l1-n 12-output-monitor, fc:l1-n 13-output-monitor, fc:l1-n 14-output-monitor, fc:l1-n 15-output-monitor, fc:l1-n 16-output-monitor, fc:l1-n 17-output-monitor, fc:l1-n 18-output-monitor, fc:l1-n 19-output-monitor, fc:l1-n 20-output-monitor, fc:l1-n 21-output-monitor, fc:l1-n 22-output-monitor, fc:l1-n 23-output-monitor, fc:l1-n 24-output-monitor, fc:l1-n 25-output-monitor, fc:l1-n 26-output-monitor, fc:l1-n 27-output-monitor, fc:l1-n 28-output-monitor, fc:l1-n 29-output-monitor, fc:l1-n 30-output-monitor, fc:l1-n 31-output-monitor, fc:l1-n 32-output-monitor, fc:l1-n 33-output-monitor, fc:l1-n 34-output-monitor, fc:l1-n 35-output-monitor, fc:l1-n 36-output-monitor, fc:l1-n 37-output-monitor, fc:l1-n 38-output-monitor, fc:l1-n 39-output-monitor, fc:l1-n 40-output-monitor, fc:l1-n 41-output-monitor, fc:l1-n 42-output-monitor, fc:l1-n 43-output-monitor, fc:l1-n 44-output-monitor, fc:l1-n 45-output-monitor, fc:l1-n 46-output-monitor, fc:l1-n 47-output-monitor, fc:l1-n 48-output-monitor, fc:l1-n 49-output-monitor, fc:l1-n 50-output-monitor, fc:l1-n 51-output-monitor, fc:l1-n 52-output-monitor, fc:l1-n 53-output-monitor, fc:l1-n 54-output-monitor, fc:l1-n 55-output-monitor, fc:l1-n 56-output-monitor, fc:l1-n 57-output-monitor, fc:l1-n 58-output-monitor, fc:l1-n 59-output-monitor, fc:l1-n 60-output-monitor, fc:l1-n 61-output-monitor, fc:l1-n 62-output-monitor, fc:l1-n 63-output-monitor, fc:l1-n 64-output-monitor, fc:l1-n 65-output-monitor, fc:l1-n 66-output-monitor, fc:l1-n 67-output-monitor, fc:l1-n 68-output-monitor, fc:l1-n 69-output-monitor, fc:l1-n 70-output-monitor, fc:l1-n 71-output-monitor, fc:l1-n 72-output-monitor, fc:l1-n 73-output-monitor, fc:l1-n 74-output-monitor, fc:l1-n 75-output-monitor, fc:l1-n 76-output-monitor, fc:l1-n 77-output-monitor, fc:l1-n 78-output-monitor, fc:l1-n 79-output-monitor, fc:l1-n 80-output-monitor, fc:l1-n 81-output-monitor, fc:l1-n 82-output-monitor, fc:l1-n 83-output-monitor, fc:l1-n 84-output-monitor, fc:l1-n 85-output-monitor, fc:l1-n 86-output-monitor, fc:l1-n 87-output-monitor, fc:l1-n 88-output-monitor, fc:l1-n 89-output-monitor, fc:l1-n 90-output-monitor, fc:l1-n 91-output-monitor, fc:l1-n 92-output-monitor, fc:l1-n 93-output-monitor, fc:l1-n 94-output-monitor, fc:l1-n 95-output-monitor, fc:l1-n 96-output-monitor, fc:l1-n 97-output-monitor, fc:l1-n 98-output-monitor, fc:l1-n 99-output-monitor]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.neurons[0].loihi_type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "loihi_model(inputs, t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, probe_selection=[\"calc\", \"sync\"], \n",
    "                                             partition=\"nahuku32\", num_chips=4, plot=False)\n",
    "output_combinations = list(zip([value[0] for (key, value) in sorted(output_values.items())], model_output))\n",
    "output_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stick.layers.InputLayer at 0x7fceec35df98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quartz\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "t_max = 2**8\n",
    "run_time = 8*t_max\n",
    "input_dims=   (6, 5,  5, 2)\n",
    "weight_dims = (32,6,5,5)\n",
    "weight_e = 500\n",
    "weight_acc = 128\n",
    "kernel_size = weight_dims[2:]\n",
    "\n",
    "l0 = quartz.layers.InputLayer(dims=input_dims, monitor=False, weight_e=weight_e, weight_acc=weight_acc)\n",
    "weights = (np.random.rand(*weight_dims)-0.5) / 5\n",
    "biases = (np.random.rand(weight_dims[0])-0.5) / 2\n",
    "l1 = quartz.layers.Conv2D(prev_layer=l0, weights=weights, biases=biases, split_output=False,\\\n",
    "                         monitor=False, weight_e=weight_e, weight_acc=weight_acc)\n",
    "l2 = quartz.layers.MonitorLayer(prev_layer=l1, weight_e=weight_e, weight_acc=weight_acc)\n",
    "\n",
    "values = np.random.rand(np.product(input_dims)//2) / 2\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "quantized_values = (values*t_max).round()/t_max\n",
    "quantized_values = quantized_values.reshape(*input_dims[:3])\n",
    "quantized_weights = (weight_acc*weights).round()/weight_acc\n",
    "quantized_biases = (biases*t_max).round()/t_max\n",
    "\n",
    "model = nn.Sequential(nn.Conv2d(in_channels=weight_dims[1], out_channels=weight_dims[0], kernel_size=kernel_size), nn.ReLU())\n",
    "model[0].weight = torch.nn.Parameter(torch.tensor(quantized_weights))\n",
    "model[0].bias = torch.nn.Parameter(torch.tensor(quantized_biases))\n",
    "model_output = model(torch.tensor(values.reshape(1, *input_dims[:3]))).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, probe_selection=[\"sync\", \"calc\"], plot=False)\n",
    "output_combinations = list(zip([value[0] for (key, value) in sorted(output_values.items())], model_output.flatten()))\n",
    "output_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quartz\n",
    "import numpy as np\n",
    "t_max = 2**8\n",
    "run_time = 8*t_max\n",
    "input_dims = (1,10,10,2)\n",
    "kernel_size = [2,2]\n",
    "\n",
    "l0 = quartz.layers.InputLayer(dims=input_dims, monitor=False)\n",
    "l1 = quartz.layers.MaxPool2D(prev_layer=l0, kernel_size=kernel_size, split_output=True, monitor=False)\n",
    "l2 = quartz.layers.MonitorLayer(prev_layer=l1)\n",
    "\n",
    "np.random.seed(seed=45)\n",
    "values = np.random.rand(np.product(dims)//2)\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "quantized_values = (values*t_max).astype(int)/t_max\n",
    "\n",
    "model = nn.Sequential(nn.MaxPool2d(kernel_size=kernel_size, stride=stride), nn.ReLU())\n",
    "model_output = model(torch.tensor(quantized_values.reshape(1, *input_dims[:3]))).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, plot=False)\n",
    "output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-0.9.5",
   "language": "python",
   "name": "nxsdk-0.9.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
