{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "t_max = 2**8\n",
    "run_time = 4*t_max\n",
    "dims = (1,10,10,2)\n",
    "n_outputs = 100\n",
    "weight_e = 500\n",
    "weight_acc = 128\n",
    "model_args = {'weight_e':weight_e, 'weight_acc':weight_acc}\n",
    "\n",
    "np.random.seed(seed=47)\n",
    "weights = (np.random.rand(n_outputs,np.product(dims)//2) - 0.5) / 5\n",
    "biases = (np.random.rand(n_outputs) - 0.5) / 2\n",
    "\n",
    "loihi_model = quartz.Network([\n",
    "    layers.InputLayer(dims=dims, **model_args),\n",
    "    layers.FullyConnected(weights=weights, biases=None, split_output=False, **model_args),\n",
    "    layers.MonitorLayer(**model_args),\n",
    "])\n",
    "\n",
    "values = np.random.rand(np.product(dims)//2)\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "\n",
    "quantized_values = (values*t_max).round()/t_max\n",
    "quantized_weights = (weight_acc*weights).round()/weight_acc\n",
    "quantized_biases = (biases*t_max).round()/t_max\n",
    "\n",
    "pt_model = nn.Sequential(\n",
    "    nn.Linear(in_features=np.product(dims[1:3]), out_features=n_outputs), \n",
    "    nn.ReLU()\n",
    ")\n",
    "pt_model[0].weight = torch.nn.Parameter(torch.tensor(quantized_weights))\n",
    "pt_model[0].bias = torch.nn.Parameter(torch.tensor(quantized_biases))\n",
    "model_output = pt_model(torch.tensor(quantized_values)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model.n_compartments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model.layers[1].blocks[0].n_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model.layers[2].n_compartments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model(inputs, t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, probe_selection=[\"calc\", \"sync\"], \n",
    "                                             partition=\"nahuku32\", num_chips=4, plot=False)\n",
    "output_combinations = list(zip([value[0] for (key, value) in sorted(output_values.items())], model_output))\n",
    "output_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quartz\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "t_max = 2**8\n",
    "run_time = 8*t_max\n",
    "input_dims=   (6, 5,  5, 2)\n",
    "weight_dims = (32,6,5,5)\n",
    "weight_e = 500\n",
    "weight_acc = 128\n",
    "kernel_size = weight_dims[2:]\n",
    "\n",
    "l0 = quartz.layers.InputLayer(dims=input_dims, monitor=False, weight_e=weight_e, weight_acc=weight_acc)\n",
    "weights = (np.random.rand(*weight_dims)-0.5) / 5\n",
    "biases = (np.random.rand(weight_dims[0])-0.5) / 2\n",
    "l1 = quartz.layers.Conv2D(prev_layer=l0, weights=weights, biases=biases, split_output=False,\\\n",
    "                         monitor=False, weight_e=weight_e, weight_acc=weight_acc)\n",
    "l2 = quartz.layers.MonitorLayer(prev_layer=l1, weight_e=weight_e, weight_acc=weight_acc)\n",
    "\n",
    "values = np.random.rand(np.product(input_dims)//2) / 2\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "quantized_values = (values*t_max).round()/t_max\n",
    "quantized_values = quantized_values.reshape(*input_dims[:3])\n",
    "quantized_weights = (weight_acc*weights).round()/weight_acc\n",
    "quantized_biases = (biases*t_max).round()/t_max\n",
    "\n",
    "model = nn.Sequential(nn.Conv2d(in_channels=weight_dims[1], out_channels=weight_dims[0], kernel_size=kernel_size), nn.ReLU())\n",
    "model[0].weight = torch.nn.Parameter(torch.tensor(quantized_weights))\n",
    "model[0].bias = torch.nn.Parameter(torch.tensor(quantized_biases))\n",
    "model_output = model(torch.tensor(values.reshape(1, *input_dims[:3]))).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, probe_selection=[\"sync\", \"calc\"], plot=False)\n",
    "output_combinations = list(zip([value[0] for (key, value) in sorted(output_values.items())], model_output.flatten()))\n",
    "output_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quartz\n",
    "import numpy as np\n",
    "t_max = 2**8\n",
    "run_time = 8*t_max\n",
    "input_dims = (1,10,10,2)\n",
    "kernel_size = [2,2]\n",
    "\n",
    "l0 = quartz.layers.InputLayer(dims=input_dims, monitor=False)\n",
    "l1 = quartz.layers.MaxPool2D(prev_layer=l0, kernel_size=kernel_size, split_output=True, monitor=False)\n",
    "l2 = quartz.layers.MonitorLayer(prev_layer=l1)\n",
    "\n",
    "np.random.seed(seed=45)\n",
    "values = np.random.rand(np.product(dims)//2)\n",
    "inputs = quartz.utils.decode_values_into_spike_input(values, t_max)\n",
    "quantized_values = (values*t_max).astype(int)/t_max\n",
    "\n",
    "model = nn.Sequential(nn.MaxPool2d(kernel_size=kernel_size, stride=stride), nn.ReLU())\n",
    "model_output = model(torch.tensor(quantized_values.reshape(1, *input_dims[:3]))).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values, spike_times = l2.run_on_loihi(run_time, t_max=t_max, input_spike_list=inputs, plot=False)\n",
    "output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-0.9.5",
   "language": "python",
   "name": "nxsdk-0.9.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
