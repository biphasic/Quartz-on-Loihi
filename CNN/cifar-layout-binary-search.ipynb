{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c537dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN.cifar_model import MobileNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import copy\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f99df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(10)\n",
    "model.load_state_dict(torch.load(\"CNN/cifar-convnet.pth\", map_location=torch.device('cpu')))\n",
    "capture = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_module = None\n",
    "new_layers = []\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.MaxPool2d, nn.BatchNorm2d, nn.Linear, nn.ReLU6, nn.ReLU, nn.Flatten)):\n",
    "        if isinstance(module, nn.BatchNorm2d) and isinstance(previous_module, nn.Conv2d):\n",
    "            new_layers[-1] = torch.nn.utils.fuse_conv_bn_eval(previous_module, module)\n",
    "        else:\n",
    "            new_layers.append(module)\n",
    "        previous_module = module\n",
    "\n",
    "folded_model = nn.Sequential(*new_layers)\n",
    "layer_list = list(folded_model.modules())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b40571",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**6\n",
    "input_dims = (3,32,32)\n",
    "pool_kernel_size = [2,2]\n",
    "\n",
    "loihi_layers = []\n",
    "for l, layer in enumerate(layer_list):\n",
    "    rectification = l < len(layer_list)-1 and isinstance(layer_list[l+1], (nn.ReLU6, nn.ReLU))\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        loihi_layers.append(layers.Conv2D(weights=layer.weight.detach().numpy(), biases=layer.bias.detach().numpy(), stride=layer.stride, padding=layer.padding, groups=layer.groups, rectifying=rectification))\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        loihi_layers.append(layers.Dense(weights=layer.weight.detach().numpy(), biases=layer.bias.detach().numpy(), rectifying=rectification))\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        loihi_layers.append(layers.MaxPool2D(kernel_size=layer.kernel_size, stride=layer.stride))\n",
    "\n",
    "all_layers = [layers.InputLayer(dims=input_dims)] + copy.deepcopy(loihi_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36209913",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model = quartz.Network(t_max, all_layers, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb1c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6b9b386",
   "metadata": {},
   "source": [
    "## see if the thing compiles without errors, otherwise reduce #neurons on that layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecb0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22020b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_board(cap, candidate):\n",
    "    if candidate + 1 >= cap: return cap, False\n",
    "    try:\n",
    "        board = layer_model(np.random.rand(*loihi_model.layers[selected_layer-1].output_dims), n_cores_per_layer=[0,candidate], partition='nahuku32', profiling=True, return_board=True)\n",
    "#         print(\"SUCCESS: Compilation succeded at {} cores for selected layer {}, cap: {}, candidate: {}\".format(candidate, selected_layer, cap, candidate))\n",
    "        cap = candidate\n",
    "        return cap, cap // 2\n",
    "    except:\n",
    "#         print(\"ERROR: Compilation failed at {} cores for selected layer {}, cap: {}, candidate: {}\".format(candidate, selected_layer, cap, candidate))\n",
    "        return cap, int(candidate + (cap-candidate) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "for selected_layer in range(1,10):\n",
    "    selected_layers = [layers.InputLayer(dims=loihi_model.layers[selected_layer-1].output_dims)] + [copy.deepcopy(loihi_layers[selected_layer-1])]\n",
    "    layer_model = quartz.Network(t_max, selected_layers, verbose=False)\n",
    "    cap = 300\n",
    "    candidate = 150\n",
    "    while True:\n",
    "        cap, candidate = compile_board(cap, candidate)\n",
    "        if candidate == False: \n",
    "            print(\"Found {} cores for selected layer {}.\".format(cap, selected_layer))\n",
    "            break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccbbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad965c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # n_cores_per_layer =      [0,15, 33, 9,5,17,17,5,17,5,3,3,1,1]\n",
    "# # new: n_cores_per_layer = [0,10,280,11,  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-1.0.0",
   "language": "python",
   "name": "nxsdk-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
