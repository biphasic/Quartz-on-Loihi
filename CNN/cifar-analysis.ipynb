{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.quantization\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from cifar_model import MobileNet\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = 'cpu'\n",
    "gpu_device = 'cuda'\n",
    "percentile = 99.9\n",
    "\n",
    "# parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "valid_dataset = datasets.CIFAR10(root='./data', train=False,transform=transform)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=valid_dataset, batch_size=1, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(10)\n",
    "model.load_state_dict(torch.load(\"./cifar-convnet.pth\", map_location=torch.device(cpu_device)))\n",
    "capture = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(model, valid_loader, device=cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold bn layers into previous conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_module = None\n",
    "new_layers = []\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.MaxPool2d, nn.BatchNorm2d, nn.Linear, nn.ReLU6, nn.ReLU, nn.Flatten)):\n",
    "        if isinstance(module, nn.BatchNorm2d) and isinstance(previous_module, nn.Conv2d):\n",
    "            new_layers[-1] = torch.nn.utils.fuse_conv_bn_eval(previous_module, module)\n",
    "        else:\n",
    "            new_layers.append(module)\n",
    "        previous_module = module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folded_model = nn.Sequential(*new_layers)\n",
    "folded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(folded_model, valid_loader, device=cpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_activations(model, percentile, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size_test = 1000\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    valid_dataset = datasets.CIFAR10(root='./data', train=False,transform=transform_test, download=False)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        activations = {}\n",
    "        def save_activation(name, mod, inp, out):\n",
    "            if name not in activations.keys():\n",
    "                activations[name] = out\n",
    "            else:\n",
    "                activations[name] = torch.cat((activations[name],out))\n",
    "\n",
    "        names = []\n",
    "        handles = []\n",
    "        max_weights_percentile = []\n",
    "        min_weights_percentile = []\n",
    "\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                handles.append(module.register_forward_hook(partial(save_activation, name)))\n",
    "                names.append(name)\n",
    "                max_weights_percentile.append(np.percentile(module.weight.cpu().numpy(), percentile).round(2))\n",
    "                min_weights_percentile.append(np.percentile(module.weight.cpu().numpy(), 100-percentile).round(2))\n",
    "\n",
    "        running_loss = 0\n",
    "        for X, y_true in valid_loader:\n",
    "            X = X.to(device)\n",
    "            y_output = model(X)\n",
    "        [handle.remove() for handle in handles] # remove forward hooks\n",
    "\n",
    "        str_output = ''.join([\"{}: [{},{}]; \".format(names[i], str(min_weights_percentile[i]), str(max_weights_percentile[i])) for i in range(len(names))])\n",
    "        print(\"\\t\" + str(percentile) + \"% weights: \" + str_output)\n",
    "\n",
    "        str_output = ''.join([\"{}: {}, \".format(name, round(np.percentile(np.maximum(activation.cpu(),0), percentile),3)) for name, activation in activations.items()])\n",
    "        print(\"\\t\" + str(percentile) + \"% activations: \" + str_output)\n",
    "    return min_weights_percentile, max_weights_percentile, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weights_percentile, max_weights_percentile, names = check_activations(folded_model, percentile, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = check_activations(model, percentile, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(zip(min_weights_percentile, max_weights_percentile))\n",
    "scaling_factors = [1/max(abs(mini), maxi) for mini, maxi in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "scaled_model = copy.deepcopy(folded_model)\n",
    "capture = scaled_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_dict = dict(zip(names, scaling_factors))\n",
    "scaling_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling_dict = {\n",
    "#  '4': 0.4854368932038835,\n",
    "#  '9': 0.37593984962406013,\n",
    "#  '14': 0.4424778761061947,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for name, module in scaled_model.named_children():\n",
    "        if name in scaling_dict:\n",
    "            if hasattr(module, 'weight'):\n",
    "                module.weight *= 1.2 #scaling_dict[name]\n",
    "            if hasattr(module, 'bias') and module.bias is not None:\n",
    "                module.bias *= 1.2 #scaling_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = check_activations(scaled_model, percentile, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(scaled_model, valid_loader, device=cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-1.0.0",
   "language": "python",
   "name": "nxsdk-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
