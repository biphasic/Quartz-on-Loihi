{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN.cifar_model import ConvNet, ConvBNReLU, Bottleneck, ConvPool\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "model = ConvNet(n_classes)\n",
    "model.load_state_dict(torch.load(\"CNN/cifar-convnet.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "previous_module = None\n",
    "new_layers = []\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.MaxPool2d, nn.BatchNorm2d, nn.Linear)):\n",
    "        if isinstance(module, nn.BatchNorm2d) and isinstance(previous_module, nn.Conv2d):\n",
    "            new_layers[-1] = torch.nn.utils.fuse_conv_bn_eval(previous_module, module)\n",
    "        else:\n",
    "            new_layers.append(module)\n",
    "        previous_module = module\n",
    "folded_model = nn.Sequential(*new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = list(folded_model.modules())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**7\n",
    "input_dims = (3,32,32)\n",
    "pool_kernel_size = [2,2]\n",
    "steps_per_image = 7*t_max\n",
    "batch_size = 10\n",
    "\n",
    "loihi_layers = [layers.Conv2D(weights=conv_layer.weight.detach().numpy(), biases=conv_layer.bias.detach().numpy(),\n",
    "                              padding=conv_layer.padding, groups=conv_layer.groups) for conv_layer in folded_model.modules() if isinstance(conv_layer, nn.Conv2d)]\n",
    "loihi_layers = [layers.InputLayer(dims=input_dims)] + loihi_layers\n",
    "\n",
    "loihi_model = quartz.Network(t_max, loihi_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loihi_model.check_block_delays(t_max, 2**3)\n",
    "#loihi_model.print_core_layout(redo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),])\n",
    "test_set = datasets.MNIST('./CNN/data', train=False, download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"Started on %a, %d %b %Y %H:%M:%S\", time.gmtime()))\n",
    "start_time = time.time()\n",
    "\n",
    "errors = []\n",
    "for inputs, target in test_loader_iter:\n",
    "    loihi_output = loihi_model(inputs.numpy(), t_max, steps_per_image=steps_per_image, partition='nahuku32_2h', \n",
    "                               logging=False, profiling=False)\n",
    "    #break\n",
    "    firsts = np.zeros((n_classes,batch_size))\n",
    "    for i, (key, values) in enumerate(sorted(loihi_model.data[1].items())[:n_classes]):\n",
    "        for iteration in range(batch_size):\n",
    "            firsts[i, iteration] = values[(values>(iteration * steps_per_image)) & (values<((iteration+1)*steps_per_image))][0]\n",
    "    loihi_results = np.argmin(firsts, axis=0)\n",
    "    positives = sum(loihi_results == target.numpy())\n",
    "    negatives = loihi_results != target.numpy()\n",
    "    error = 100*(1-positives/len(target))\n",
    "    errors.append(error)\n",
    "    print(\"Correctly detected {} out of {}: {}% error\".format(positives, len(target), error))\n",
    "    break\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, target = next(test_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firsts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(loihi_model.data[1].items())[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loihi_output.rawPowerTimeStamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(errors)/len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"{}\\n\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firsts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(loihi_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-0.9.8",
   "language": "python",
   "name": "nxsdk-0.9.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
