{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN.cifar_model import MobileNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(10)\n",
    "model.load_state_dict(torch.load(\"./CNN/models/cifar-convnet.pth\", map_location=torch.device('cpu')))\n",
    "capture = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fold batchnorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_module = None\n",
    "new_layers = []\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.MaxPool2d, nn.BatchNorm2d, nn.Linear, nn.ReLU6, nn.ReLU, nn.Flatten)):\n",
    "        if isinstance(module, nn.BatchNorm2d) and isinstance(previous_module, nn.Conv2d):\n",
    "            new_layers[-1] = torch.nn.utils.fuse_conv_bn_eval(previous_module, module)\n",
    "        else:\n",
    "            new_layers.append(module)\n",
    "        previous_module = module\n",
    "\n",
    "folded_model = nn.Sequential(*new_layers)\n",
    "layer_list = list(folded_model.modules())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build Quartz model from folded pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**6\n",
    "input_dims = (3,32,32)\n",
    "pool_kernel_size = [2,2]\n",
    "\n",
    "loihi_layers = []\n",
    "for l, layer in enumerate(layer_list):\n",
    "    rectification = l < len(layer_list)-1 and isinstance(layer_list[l+1], (nn.ReLU6, nn.ReLU))\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        loihi_layers.append(layers.Conv2D(weights=layer.weight.detach().numpy(), biases=layer.bias.detach().numpy(), stride=layer.stride, padding=layer.padding, groups=layer.groups, rectifying=rectification))\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        loihi_layers.append(layers.Dense(weights=layer.weight.detach().numpy(), biases=layer.bias.detach().numpy(), rectifying=rectification))\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        loihi_layers.append(layers.MaxPool2D(kernel_size=layer.kernel_size, stride=layer.stride))\n",
    "\n",
    "loihi_layers = [layers.InputLayer(dims=input_dims)] + loihi_layers\n",
    "# loihi_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_cores_per_layer = [0,300,225,275,400,400,600,450,400,350,250,150,100,10]\n",
    "print(n_cores_per_layer)\n",
    "sum(n_cores_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model = quartz.Network(t_max, loihi_layers, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps_per_layer = [layer.n_output_compartments() + layer.n_bias_compartments() for layer in loihi_layers]\n",
    "[round(100*n_comps / ((n_cores+1e-8) * 1024),2) for n_cores, n_comps in zip(n_cores_per_layer, n_comps_per_layer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conns_per_layer = [layer.n_outgoing_connections() for layer in loihi_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n_conns // n_cores for n_cores, n_conns in zip(n_cores_per_layer[1:], n_conns_per_layer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),])\n",
    "test_set = datasets.CIFAR10('./CNN/data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "inputs, targets = next(iter(test_loader))\n",
    "try:\n",
    "    energy_probe = loihi_model(inputs.detach().numpy(), n_cores_per_layer=n_cores_per_layer, partition='nahuku32', logging=True, profiling=True)\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# batch_size = 1000\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# errors = []\n",
    "# avg_first_spikes = []\n",
    "# for b, (inputs, target) in enumerate(iter(test_loader)):\n",
    "#     loihi_output_values = loihi_model(inputs.detach().numpy(), n_cores_per_layer=n_cores_per_layer, partition='nahuku32_2h', logging=True, profiling=False)\n",
    "#     # some of the outputs might spike multiple times so instead of the output values, we rely on the first spikes for every batch\n",
    "#     avg_first_spikes.append(np.mean([time-i*loihi_model.steps_per_image for i, time in enumerate(np.min(loihi_model.first_spikes, axis=0))]))\n",
    "#     print(\"Average first spike: \" + str(avg_first_spikes[-1]))\n",
    "#     classification_results = np.argmin(loihi_model.first_spikes, axis=0)\n",
    "#     positives = sum(classification_results == target.numpy())\n",
    "#     errors.append(100*(1-positives/len(target)))\n",
    "#     print(\"Correctly detected {} out of {}: {}% error\".format(positives, len(target), str(errors[-1])))    \n",
    "#     print(\"Batch {} finished within {} seconds.\".format(b, time.time() - start_time))\n",
    "#     start_time = time.time()\n",
    "\n",
    "# print(\"Average first spike for test set: {}\".format(np.sum(avg_first_spikes)/len(avg_first_spikes)))\n",
    "# print(\"Accuracy error for test set: {}\".format(np.sum(errors)/len(errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"results.txt\", \"a\") as myfile:\n",
    "#     myfile.write(\"{}\\n\".format(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-1.0.0",
   "language": "python",
   "name": "nxsdk-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
