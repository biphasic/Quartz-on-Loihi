{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN.mnist_model import ConvNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import quartz\n",
    "from quartz import layers\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(10)\n",
    "model.load_state_dict(torch.load(\"CNN/mnist-convnet.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "class Lenet1(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Lenet1, self).__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    model.conv1,\n",
    "                    nn.ReLU(),\n",
    "                    model.pool1,\n",
    "                    model.conv2,\n",
    "                    nn.ReLU(),\n",
    "                    model.pool2,\n",
    "                    #model.drop2,\n",
    "                    model.conv3,\n",
    "                    nn.ReLU(),\n",
    "#                     #model.drop3,\n",
    "#                     nn.Flatten(),\n",
    "#                     model.fc1,\n",
    "#                     nn.ReLU(),\n",
    "                )\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                return x\n",
    "\n",
    "layer = Lenet1()\n",
    "layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_biases(model):\n",
    "    parameters = list(model.parameters())\n",
    "    weights = [weight.detach().numpy().copy() for weight in parameters[::2][::2]]\n",
    "    biases = [bias.detach().numpy().copy() for bias in parameters[1::2][::2]]\n",
    "    return weights, biases\n",
    "\n",
    "weights, biases = get_weights_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([weight.max() for weight in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([weight.min() for weight in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights[1] /= 1.5\n",
    "# biases[1] /= 1.5\n",
    "# weights[2] /= 1.6\n",
    "# biases[2] /= 1.6\n",
    "# weights[3] /= 3\n",
    "# biases[3] /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     layer.features[3].weight /= 1.5\n",
    "#     layer.features[3].bias /= 1.5\n",
    "#     layer.features[6].weight /= 1.6\n",
    "#     layer.features[6].bias /= 1.6\n",
    "#     layer.features[9].weight /= 3\n",
    "#     layer.features[9].bias /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**6\n",
    "input_dims = (1,28,28)\n",
    "pool_kernel_size = [2,2]\n",
    "batch_size = 1\n",
    "\n",
    "loihi_model = quartz.Network(t_max, [\n",
    "    layers.InputLayer(dims=input_dims),\n",
    "    layers.Conv2D(weights=weights[0], biases=biases[0]),\n",
    "    layers.MaxPool2D(kernel_size=pool_kernel_size),\n",
    "    layers.Conv2D(weights=weights[1], biases=biases[1]),\n",
    "    layers.MaxPool2D(kernel_size=pool_kernel_size),\n",
    "    layers.Conv2D(weights=weights[2], biases=biases[2]),\n",
    "#     layers.Dense(weights=weights[3], biases=biases[3], rectifying=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),])\n",
    "test_set = datasets.MNIST('./CNN/data', train=False, download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, targets = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loihi_model.layers[1].blocks[0]\n",
    "# [len(block.connections) for block in loihi_model.layers[3].blocks if len(block.connections) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loihi_output = loihi_model(samples.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = layer(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loihi_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(loihi_output.flatten()) == len(layer_output.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list(zip(loihi_output.flatten(), layer_output.detach().cpu().numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxsdk-0.9.8",
   "language": "python",
   "name": "nxsdk-0.9.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
